<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8">
<meta name="viewport" content="width=device-width, initial-scale=1.0">
<title>Statistics Cheatsheet</title>
<style>
@import url('https://fonts.googleapis.com/css2?family=Inter:wght@300;400;500;600;700;800&family=JetBrains+Mono:wght@400;500&display=swap');
:root {
  --bg: #0f172a; --surface: #1e293b; --surface2: #334155;
  --text: #e2e8f0; --text-muted: #94a3b8; --text-dim: #64748b;
  --accent: #3b82f6; --accent2: #8b5cf6; --accent3: #06b6d4;
  --green: #22c55e; --red: #ef4444; --yellow: #eab308; --orange: #f97316;
  --code-bg: #0d1117; --card-border: rgba(59,130,246,0.15);
}
* { margin:0; padding:0; box-sizing:border-box; }
body { font-family:'Inter',sans-serif; background:var(--bg); color:var(--text);
       line-height:1.7; font-size:14px; }
.container { max-width:900px; margin:0 auto; padding:40px 24px; }
.cover { text-align:center; padding:80px 0 60px; border-bottom:1px solid var(--surface2); margin-bottom:40px; }
.cover h1 { font-size:3.2em; font-weight:800; background:linear-gradient(135deg,var(--accent),var(--accent2),var(--accent3));
             -webkit-background-clip:text; -webkit-text-fill-color:transparent; margin-bottom:8px; letter-spacing:-1px; }
.cover .sub { font-size:1.1em; color:var(--text-muted); margin-bottom:24px; }
.cover .tags { display:flex; flex-wrap:wrap; justify-content:center; gap:8px; }
.cover .tag { background:var(--surface); border:1px solid var(--card-border); padding:4px 14px;
              border-radius:20px; font-size:0.8em; color:var(--accent3); }
.toc { background:var(--surface); border:1px solid var(--card-border); border-radius:16px;
       padding:28px 32px; margin-bottom:40px; }
.toc h2 { font-size:1.3em; color:var(--accent); margin-bottom:16px; display:flex; align-items:center; gap:8px; }
.toc-grid { display:grid; grid-template-columns:1fr 1fr; gap:6px 24px; }
.toc a { color:var(--text-muted); text-decoration:none; font-size:0.9em; padding:4px 0;
         display:block; transition:color .2s; }
.toc a:hover { color:var(--accent); }
.toc a .num { color:var(--accent); font-weight:600; margin-right:6px; }
.section { margin-bottom:48px; }
.section-header { background:linear-gradient(135deg,var(--surface),var(--surface2));
                  border:1px solid var(--card-border); border-radius:12px;
                  padding:16px 24px; margin-bottom:20px; }
.section-header h2 { font-size:1.5em; font-weight:700; color:var(--accent);
                     display:flex; align-items:center; gap:10px; }
.section-header h2 .icon { font-size:1.2em; }
h3 { color:var(--accent2); font-size:1.1em; font-weight:600; margin:24px 0 10px;
     padding-left:12px; border-left:3px solid var(--accent2); }
h4 { color:var(--accent3); font-size:0.95em; font-weight:600; margin:16px 0 8px; }
p { margin-bottom:10px; color:var(--text); }
ul, ol { margin:8px 0 12px 20px; }
li { margin-bottom:4px; color:var(--text); }
.formula { background:var(--code-bg); border:1px solid var(--card-border); border-left:4px solid var(--accent2);
           border-radius:8px; padding:14px 20px; margin:12px 0; font-family:'JetBrains Mono',monospace;
           font-size:0.95em; color:#c9d1d9; overflow-x:auto; }
.formula .label { font-size:0.75em; color:var(--accent2); text-transform:uppercase;
                  letter-spacing:1px; margin-bottom:6px; display:block; font-family:'Inter',sans-serif; }
pre { background:var(--code-bg); border:1px solid var(--surface2); border-radius:10px;
      padding:16px 20px; margin:12px 0; overflow-x:auto; position:relative; }
pre .lang { position:absolute; top:8px; right:12px; font-size:0.7em; color:var(--text-dim);
            font-family:'Inter',sans-serif; text-transform:uppercase; letter-spacing:1px; }
code { font-family:'JetBrains Mono',monospace; font-size:0.85em; color:#c9d1d9; line-height:1.6; }
p code, li code, td code { background:var(--surface2); padding:2px 6px; border-radius:4px; font-size:0.85em; color:var(--accent3); }
table { width:100%; border-collapse:collapse; margin:12px 0 16px; border-radius:8px; overflow:hidden; }
thead th { background:linear-gradient(135deg,var(--accent),var(--accent2)); color:#fff;
           padding:10px 14px; font-weight:600; font-size:0.85em; text-transform:uppercase;
           letter-spacing:0.5px; text-align:center; }
td { padding:8px 14px; border-bottom:1px solid var(--surface2); text-align:center; font-size:0.9em; }
tr:nth-child(even) td { background:var(--surface); }
tr:hover td { background:rgba(59,130,246,0.08); }
.tip { background:rgba(34,197,94,0.08); border:1px solid rgba(34,197,94,0.3);
       border-left:4px solid var(--green); border-radius:8px; padding:12px 16px;
       margin:12px 0; font-size:0.9em; }
.tip::before { content:'\1F4A1 '; }
.warning { background:rgba(245,158,11,0.08); border:1px solid rgba(245,158,11,0.3);
           border-left:4px solid var(--orange); border-radius:8px; padding:12px 16px;
           margin:12px 0; font-size:0.9em; }
.warning::before { content:'\26A0\FE0F '; }
.tree { background:var(--code-bg); border:1px solid var(--surface2); border-radius:10px;
        padding:20px; margin:12px 0; font-family:'JetBrains Mono',monospace;
        font-size:0.82em; line-height:1.8; white-space:pre; overflow-x:auto; color:#c9d1d9; }
.vs { display:grid; grid-template-columns:1fr 1fr; gap:12px; margin:12px 0; }
.vs-card { background:var(--surface); border:1px solid var(--card-border); border-radius:10px; padding:16px; }
.vs-card h4 { margin-top:0; border:none; padding:0; }
@media print {
  body { background:#fff; color:#1e293b; font-size:11px; }
  .container { max-width:100%; padding:0; }
  .cover h1 { -webkit-text-fill-color:#1e40af; background:none; }
  .section-header { background:#f1f5f9; border-color:#cbd5e1; }
  .section-header h2 { color:#1e40af; }
  h3 { color:#6d28d9; border-color:#6d28d9; }
  pre, .formula, .tree { background:#f8fafc; border-color:#e2e8f0; }
  code { color:#1e293b; }
  .toc { background:#f8fafc; }
  table thead th { background:#2563eb; }
  td { border-color:#e2e8f0; }
  tr:nth-child(even) td { background:#f8fafc; }
  .tip { background:#f0fdf4; border-color:#86efac; }
  .warning { background:#fffbeb; border-color:#fcd34d; }
  .section { page-break-inside:avoid; }
}
</style>
</head>
<body>
<div class="container">
<div class="cover">
  <h1>STATISTICS CHEATSHEET</h1>
  <p class="sub">Comprehensive review guide with Python code examples</p>
  <div class="tags">
    <span class="tag">Shapiro-Wilk</span><span class="tag">Levene</span>
    <span class="tag">T-Test</span><span class="tag">Z-Score</span>
    <span class="tag">ANOVA</span><span class="tag">Chi-Square</span>
    <span class="tag">A/B Test</span><span class="tag">Regression</span>
    <span class="tag">Bayesian</span><span class="tag">Power Analysis</span>
  </div>
</div>
<div class="toc">
  <h2>ğŸ“‘ Table of Contents</h2>
  <div class="toc-grid"><a href="#s1"><span class="num">01</span>Descriptive Statistics</a>
<a href="#s2"><span class="num">02</span>Probability Distributions</a>
<a href="#s3"><span class="num">03</span>Z-Score</a>
<a href="#s4"><span class="num">04</span>Confidence Intervals</a>
<a href="#s5"><span class="num">05</span>Hypothesis Testing</a>
<a href="#s6"><span class="num">06</span>Normality Tests</a>
<a href="#s7"><span class="num">07</span>Variance Homogeneity â€” Levene</a>
<a href="#s8"><span class="num">08</span>T-Test</a>
<a href="#s9"><span class="num">09</span>Z-Test</a>
<a href="#s10"><span class="num">10</span>ANOVA</a>
<a href="#s11"><span class="num">11</span>Chi-Square Test</a>
<a href="#s12"><span class="num">12</span>Correlation & Regression</a>
<a href="#s13"><span class="num">13</span>Non-Parametric Tests</a>
<a href="#s14"><span class="num">14</span>Effect Size</a>
<a href="#s15"><span class="num">15</span>Power Analysis</a>
<a href="#s16"><span class="num">16</span>A/B Testing</a>
<a href="#s17"><span class="num">17</span>Bayesian Basics</a>
<a href="#s18"><span class="num">18</span>Which Test to Use?</a>
</div>
</div>

<div class="section" id="s1">
  <div class="section-header"><h2><span class="icon">ğŸ“</span> 1. Descriptive Statistics</h2></div>
  
<h3>Measures of Central Tendency</h3>
<table><thead><tr><th>Measure</th><th>Formula</th><th>When?</th></tr></thead><tbody>
<tr><td><strong>Mean</strong></td><td><code>xÌ„ = Î£xáµ¢ / n</code></td><td>Symmetric distributions</td></tr>
<tr><td><strong>Median</strong></td><td>Middle of sorted data</td><td>Skewed data, outliers</td></tr>
<tr><td><strong>Mode</strong></td><td>Most frequent value</td><td>Categorical data</td></tr>
</tbody></table>
<h3>Spread & Shape</h3>
<div class="formula"><span class="label">Sample Variance</span>sÂ² = Î£(xáµ¢ - xÌ„)Â² / (n - 1)</div>
<div class="formula"><span class="label">Standard Deviation</span>s = âˆšsÂ²</div>
<table><thead><tr><th>Measure</th><th>= 0</th><th>&gt; 0</th><th>&lt; 0</th></tr></thead><tbody>
<tr><td><strong>Skewness</strong></td><td>Symmetric</td><td>Right-skewed</td><td>Left-skewed</td></tr>
<tr><td><strong>Kurtosis</strong></td><td>Normal</td><td>Heavy-tailed</td><td>Light-tailed</td></tr>
</tbody></table>
<pre><span class="lang">Python</span><code>import numpy as np
from scipy import stats

data = [23, 45, 12, 67, 34, 89, 56, 78, 90, 43]
print(f"Mean:     {np.mean(data):.2f}")
print(f"Median:   {np.median(data):.2f}")
print(f"Std Dev:  {np.std(data, ddof=1):.2f}")
print(f"Skewness: {stats.skew(data):.4f}")
print(f"Kurtosis: {stats.kurtosis(data):.4f}")</code></pre>

</div>
<div class="section" id="s2">
  <div class="section-header"><h2><span class="icon">ğŸ””</span> 2. Probability Distributions</h2></div>
  
<h3>Normal Distribution</h3>
<p><strong>Central Limit Theorem:</strong> When nâ‰¥30, sample means are approximately normal.</p>
<div class="formula"><span class="label">68-95-99.7 Rule</span>68% â†’ Î¼ Â± 1Ïƒ &nbsp;&nbsp; 95% â†’ Î¼ Â± 2Ïƒ &nbsp;&nbsp; 99.7% â†’ Î¼ Â± 3Ïƒ</div>
<h3>Binomial Distribution</h3>
<div class="formula"><span class="label">PMF</span>P(X = k) = C(n,k) Â· p^k Â· (1-p)^(n-k)</div>
<h3>Poisson Distribution</h3>
<div class="formula"><span class="label">PMF</span>P(X = k) = (Î»^k Â· e^(-Î»)) / k!</div>
<pre><span class="lang">Python</span><code>from scipy.stats import norm, binom, poisson

print(f"P(Z < 1.96) = {norm.cdf(1.96):.4f}")
print(f"Binom(10,0.5) P(X=6) = {binom.pmf(6, 10, 0.5):.4f}")
print(f"Poisson(3) P(X=5) = {poisson.pmf(5, 3):.4f}")</code></pre>

</div>
<div class="section" id="s3">
  <div class="section-header"><h2><span class="icon">ğŸ“Š</span> 3. Z-Score</h2></div>
  
<p>How many standard deviations a value is from the mean.</p>
<div class="formula"><span class="label">Single Value</span>z = (x - Î¼) / Ïƒ</div>
<div class="formula"><span class="label">Sample Mean</span>z = (xÌ„ - Î¼â‚€) / (Ïƒ / âˆšn)</div>
<table><thead><tr><th>z</th><th>One-tailed P</th><th>Two-tailed P</th></tr></thead><tbody>
<tr><td>1.645</td><td>0.050</td><td>0.100</td></tr>
<tr><td>1.960</td><td>0.025</td><td>0.050</td></tr>
<tr><td>2.576</td><td>0.005</td><td>0.010</td></tr>
</tbody></table>
<pre><span class="lang">Python</span><code>from scipy.stats import norm

x, mu, sigma = 85, 70, 10
z = (x - mu) / sigma
print(f"z = {z:.2f}")
print(f"P(Z < {z})  = {norm.cdf(z):.4f}")
print(f"P(Z > {z})  = {1 - norm.cdf(z):.4f}")
print(f"Two-tailed  = {2*(1 - norm.cdf(abs(z))):.4f}")
print(f"Critical z (Î±=0.05) = {norm.ppf(0.975):.4f}")</code></pre>

</div>
<div class="section" id="s4">
  <div class="section-header"><h2><span class="icon">ğŸ¯</span> 4. Confidence Intervals</h2></div>
  
<div class="formula"><span class="label">Ïƒ known or n â‰¥ 30</span>CI = xÌ„ Â± z* Â· (Ïƒ / âˆšn)</div>
<div class="formula"><span class="label">Ïƒ unknown and n &lt; 30</span>CI = xÌ„ Â± t* Â· (s / âˆšn)</div>
<table><thead><tr><th>Level</th><th>z*</th></tr></thead><tbody>
<tr><td>90%</td><td>1.645</td></tr><tr><td>95%</td><td>1.960</td></tr><tr><td>99%</td><td>2.576</td></tr>
</tbody></table>
<pre><span class="lang">Python</span><code>import numpy as np
from scipy import stats

data = np.random.normal(100, 15, size=50)
se = stats.sem(data)
ci = stats.t.interval(0.95, df=len(data)-1, loc=np.mean(data), scale=se)
print(f"Mean: {np.mean(data):.2f}")
print(f"95% CI: ({ci[0]:.2f}, {ci[1]:.2f})")</code></pre>
<div class="tip"><strong>Interpretation:</strong> If we repeat this 100 times, ~95 of those intervals would contain the true parameter.</div>

</div>
<div class="section" id="s5">
  <div class="section-header"><h2><span class="icon">âš–ï¸</span> 5. Hypothesis Testing</h2></div>
  
<h3>Steps</h3>
<ol><li><strong>Hâ‚€:</strong> No effect / no difference</li><li><strong>Hâ‚:</strong> Effect exists</li>
<li><strong>Set Î±:</strong> Usually 0.05</li><li><strong>Compute test statistic</strong></li>
<li><strong>Find p-value</strong></li><li><strong>Decision:</strong> p &lt; Î± â†’ Reject Hâ‚€</li></ol>
<h3>Error Types</h3>
<table><thead><tr><th></th><th>Hâ‚€ True</th><th>Hâ‚€ False</th></tr></thead><tbody>
<tr><td><strong>Reject Hâ‚€</strong></td><td>âŒ Type I (Î±)</td><td>âœ… Correct (Power)</td></tr>
<tr><td><strong>Fail to Reject</strong></td><td>âœ… Correct</td><td>âŒ Type II (Î²)</td></tr>
</tbody></table>

</div>
<div class="section" id="s6">
  <div class="section-header"><h2><span class="icon">ğŸ“ˆ</span> 6. Normality Tests</h2></div>
  
<h3>Shapiro-Wilk</h3>
<p>Most reliable normality test (n &lt; 5000). Hâ‚€: Data is normal. p &gt; 0.05 â†’ Normal âœ…</p>
<pre><span class="lang">Python</span><code>from scipy.stats import shapiro, normaltest
import numpy as np

normal_data = np.random.normal(50, 10, 100)
skewed_data = np.random.exponential(5, 100)

stat, p = shapiro(normal_data)
print(f"Shapiro â†’ W={stat:.4f}, p={p:.4f}")
print("Normal âœ…" if p > 0.05 else "Not normal âŒ")</code></pre>
<div class="tip"><strong>Practical:</strong> When n &gt; 30, CLT makes parametric tests generally safe.</div>

</div>
<div class="section" id="s7">
  <div class="section-header"><h2><span class="icon">âš–ï¸</span> 7. Variance Homogeneity â€” Levene</h2></div>
  
<p>Tests if groups have equal variances. Prerequisite for t-test and ANOVA.</p>
<p><strong>Hâ‚€:</strong> Ïƒâ‚Â² = Ïƒâ‚‚Â² &nbsp;|&nbsp; p &gt; 0.05 â†’ Homogeneous âœ…</p>
<table><thead><tr><th>Test</th><th>Advantage</th><th>Disadvantage</th></tr></thead><tbody>
<tr><td><strong>Levene</strong></td><td>Doesn't assume normality</td><td>Slightly less powerful</td></tr>
<tr><td><strong>Bartlett</strong></td><td>Powerful under normality</td><td>Sensitive to violations</td></tr>
</tbody></table>
<pre><span class="lang">Python</span><code>from scipy.stats import levene
import numpy as np

group_a = np.random.normal(50, 10, 50)
group_c = np.random.normal(48, 25, 50)

stat, p = levene(group_a, group_c)
print(f"Levene W={stat:.4f}, p={p:.4f}")
print("Homogeneous âœ…" if p > 0.05 else "Heterogeneous âŒ")</code></pre>
<div class="warning"><strong>If not homogeneous:</strong> Use <code>equal_var=False</code> (Welch) for t-test, Kruskal-Wallis for ANOVA.</div>

</div>
<div class="section" id="s8">
  <div class="section-header"><h2><span class="icon">ğŸ”¬</span> 8. T-Test</h2></div>
  
<h3>One-Sample T-Test</h3>
<div class="formula"><span class="label">Formula</span>t = (xÌ„ - Î¼â‚€) / (s / âˆšn), &nbsp; df = n - 1</div>
<pre><span class="lang">Python</span><code>from scipy.stats import ttest_1samp
scores = [78, 82, 85, 90, 74, 88, 92, 79, 83, 87]
t, p = ttest_1samp(scores, popmean=80)
print(f"t={t:.4f}, p={p:.4f} â†’ {'Reject' if p<0.05 else 'Fail to reject'}")</code></pre>
<h3>Independent Two-Sample</h3>
<p><strong>Prerequisites:</strong> â‘  Normality â‘¡ Variance homogeneity â‘¢ Independence</p>
<pre><span class="lang">Python</span><code>from scipy.stats import ttest_ind, levene
import numpy as np

drug = np.random.normal(120, 15, 30)
placebo = np.random.normal(130, 15, 30)

_, p_lev = levene(drug, placebo)
t, p = ttest_ind(drug, placebo, equal_var=(p_lev > 0.05))
print(f"t={t:.4f}, p={p:.4f}")
print("Significant âœ…" if p < 0.05 else "Not significant âŒ")</code></pre>
<h3>Paired T-Test</h3>
<pre><span class="lang">Python</span><code>from scipy.stats import ttest_rel
before  = [120, 135, 128, 140, 132, 145, 138, 130, 142, 136]
after   = [115, 125, 122, 130, 128, 135, 130, 120, 132, 128]
t, p = ttest_rel(before, after)
print(f"t={t:.4f}, p={p:.4f} â†’ {'Effective âœ…' if p<0.05 else 'Ineffective âŒ'}")</code></pre>

</div>
<div class="section" id="s9">
  <div class="section-header"><h2><span class="icon">ğŸ“</span> 9. Z-Test</h2></div>
  
<p>Large-sample (<strong>nâ‰¥30</strong>) version of t-test when <strong>Ïƒ is known</strong>.</p>
<div class="formula"><span class="label">Formula</span>z = (xÌ„ - Î¼â‚€) / (Ïƒ / âˆšn)</div>
<pre><span class="lang">Python</span><code>import numpy as np
from scipy.stats import norm

measurements = np.random.normal(503, 10, 50)
z = (np.mean(measurements) - 500) / (10 / np.sqrt(50))
p = 2 * (1 - norm.cdf(abs(z)))
print(f"z={z:.4f}, p={p:.4f}")</code></pre>
<table><thead><tr><th>Feature</th><th>Z-Test</th><th>T-Test</th></tr></thead><tbody>
<tr><td>Ïƒ known?</td><td>Yes</td><td>No</td></tr>
<tr><td>Sample</td><td>n â‰¥ 30</td><td>Any</td></tr>
<tr><td>Distribution</td><td>Normal (CLT)</td><td>t distribution</td></tr>
</tbody></table>

</div>
<div class="section" id="s10">
  <div class="section-header"><h2><span class="icon">ğŸ“Š</span> 10. ANOVA</h2></div>
  
<h3>One-Way ANOVA</h3>
<p>Compares 3+ group means. Hâ‚€: Î¼â‚ = Î¼â‚‚ = ... = Î¼â‚–</p>
<div class="formula"><span class="label">F Statistic</span>F = MSB / MSW = (Between-group variance) / (Within-group variance)</div>
<pre><span class="lang">Python</span><code>from scipy.stats import f_oneway
import numpy as np

a = np.random.normal(75, 8, 30)
b = np.random.normal(80, 8, 30)
c = np.random.normal(78, 8, 30)

F, p = f_oneway(a, b, c)
print(f"F={F:.4f}, p={p:.4f}")

from statsmodels.stats.multicomp import pairwise_tukeyhsd
data = np.concatenate([a, b, c])
groups = ['A']*30 + ['B']*30 + ['C']*30
print(pairwise_tukeyhsd(data, groups, alpha=0.05))</code></pre>

</div>
<div class="section" id="s11">
  <div class="section-header"><h2><span class="icon">ğŸ²</span> 11. Chi-Square Test</h2></div>
  
<h3>Test of Independence</h3>
<p>Is there a relationship between two categorical variables?</p>
<pre><span class="lang">Python</span><code>from scipy.stats import chi2_contingency, chisquare
import numpy as np

table = np.array([[50, 30], [20, 100]])
chi2, p, df, expected = chi2_contingency(table)
print(f"Ï‡Â²={chi2:.4f}, p={p:.6f} â†’ {'Related' if p<0.05 else 'Independent'}")

# Goodness of fit
observed = [18, 22, 20, 25, 15]
chi2, p = chisquare(observed, f_exp=[20]*5)
print(f"Ï‡Â²={chi2:.4f}, p={p:.4f} â†’ {'Biased' if p<0.05 else 'Fair'}")</code></pre>

</div>
<div class="section" id="s12">
  <div class="section-header"><h2><span class="icon">ğŸ“‰</span> 12. Correlation & Regression</h2></div>
  
<table><thead><tr><th>|r|</th><th>Interpretation</th></tr></thead><tbody>
<tr><td>0.00 â€“ 0.29</td><td>Weak</td></tr><tr><td>0.30 â€“ 0.69</td><td>Moderate</td></tr><tr><td>0.70 â€“ 1.00</td><td>Strong</td></tr>
</tbody></table>
<div class="formula"><span class="label">Simple Linear Regression</span>Å· = Î²â‚€ + Î²â‚Â·x &nbsp;&nbsp; RÂ² = Explained / Total variance</div>
<pre><span class="lang">Python</span><code>from scipy.stats import pearsonr, spearmanr
from sklearn.linear_model import LinearRegression
import numpy as np

x = np.random.uniform(1, 10, 50)
y = 50 + 4*x + np.random.normal(0, 5, 50)

r, p = pearsonr(x, y)
rho, p2 = spearmanr(x, y)
print(f"Pearson r={r:.4f}, Spearman Ï={rho:.4f}")

model = LinearRegression().fit(x.reshape(-1,1), y)
print(f"Å· = {model.intercept_:.2f} + {model.coef_[0]:.2f}Â·x")
print(f"RÂ² = {model.score(x.reshape(-1,1), y):.4f}")</code></pre>

</div>
<div class="section" id="s13">
  <div class="section-header"><h2><span class="icon">ğŸ”„</span> 13. Non-Parametric Tests</h2></div>
  
<table><thead><tr><th>Parametric</th><th>Non-Parametric</th><th>Scenario</th></tr></thead><tbody>
<tr><td>Independent t</td><td><strong>Mann-Whitney U</strong></td><td>2 independent groups</td></tr>
<tr><td>Paired t</td><td><strong>Wilcoxon</strong></td><td>2 dependent groups</td></tr>
<tr><td>One-way ANOVA</td><td><strong>Kruskal-Wallis</strong></td><td>3+ independent groups</td></tr>
</tbody></table>
<pre><span class="lang">Python</span><code>from scipy.stats import mannwhitneyu, wilcoxon, kruskal
import numpy as np

g1 = np.random.exponential(5, 30)
g2 = np.random.exponential(8, 30)

U, p = mannwhitneyu(g1, g2, alternative='two-sided')
print(f"Mann-Whitney U={U:.0f}, p={p:.4f}")

before = [85, 90, 78, 92, 88, 76, 95, 80, 83, 89]
after  = [90, 95, 82, 96, 92, 82, 98, 86, 88, 93]
W, p2 = wilcoxon(before, after)
print(f"Wilcoxon W={W:.0f}, p={p2:.4f}")</code></pre>

</div>
<div class="section" id="s14">
  <div class="section-header"><h2><span class="icon">ğŸ“</span> 14. Effect Size</h2></div>
  
<p>p-value: "Is there a difference?" â†’ Effect size: <strong>"How big?"</strong></p>
<div class="formula"><span class="label">Cohen's d</span>d = (xÌ„â‚ - xÌ„â‚‚) / s_pooled &nbsp;&nbsp; (0.2=Small, 0.5=Medium, 0.8=Large)</div>
<div class="formula"><span class="label">Eta-squared (ANOVA)</span>Î·Â² = SS_between / SS_total &nbsp;&nbsp; (0.01=Small, 0.06=Medium, 0.14=Large)</div>
<pre><span class="lang">Python</span><code>import numpy as np
def cohens_d(g1, g2):
    n1, n2 = len(g1), len(g2)
    pooled = np.sqrt(((n1-1)*np.var(g1,ddof=1)+(n2-1)*np.var(g2,ddof=1))/(n1+n2-2))
    return (np.mean(g1) - np.mean(g2)) / pooled

d = cohens_d(np.random.normal(120,15,30), np.random.normal(130,15,30))
print(f"Cohen's d = {d:.4f}")</code></pre>

</div>
<div class="section" id="s15">
  <div class="section-header"><h2><span class="icon">âš¡</span> 15. Power Analysis</h2></div>
  
<p>Done <strong>BEFORE</strong> the test. 4 components (give 3, compute 4th):</p>
<ol><li>Effect size (d)</li><li>Î± (0.05)</li><li>Power (0.80)</li><li>Sample size (n)</li></ol>
<pre><span class="lang">Python</span><code>from statsmodels.stats.power import TTestIndPower

analysis = TTestIndPower()
for d in [0.2, 0.5, 0.8]:
    n = analysis.solve_power(effect_size=d, alpha=0.05, power=0.8)
    print(f"d={d} â†’ n={n:.0f} (per group)")</code></pre>

</div>
<div class="section" id="s16">
  <div class="section-header"><h2><span class="icon">ğŸ§ª</span> 16. A/B Testing</h2></div>
  
<h3>Workflow</h3>
<ol><li>State hypothesis</li><li>Define metric (conversion, CTR, revenue)</li>
<li>Calculate sample size</li><li>Run experiment</li><li>Evaluate results</li></ol>
<pre><span class="lang">Python</span><code>from statsmodels.stats.proportion import proportions_ztest, proportion_confint
from statsmodels.stats.proportion import proportion_effectsize
from statsmodels.stats.power import NormalIndPower
import numpy as np

# Control: 120/1000, Test: 145/1000
z, p = proportions_ztest([120,145], [1000,1000], alternative='smaller')
print(f"z={z:.4f}, p={p:.4f}")
if p < 0.05:
    lift = (145/1000 - 120/1000) / (120/1000) * 100
    print(f"âœ… Lift: +{lift:.1f}%")

effect = proportion_effectsize(0.10, 0.12)
n = NormalIndPower().solve_power(effect, alpha=0.05, power=0.80)
print(f"MDE 10%â†’12%: n = {n:.0f} per group")</code></pre>
<h3>Common Pitfalls</h3>
<table><thead><tr><th>Pitfall</th><th>Solution</th></tr></thead><tbody>
<tr><td><strong>Peeking</strong></td><td>Pre-determine n, wait</td></tr>
<tr><td><strong>Multiple testing</strong></td><td>Bonferroni: Î±_new = Î±/k</td></tr>
<tr><td><strong>Simpson's paradox</strong></td><td>Segment analysis</td></tr>
<tr><td><strong>Novelty effect</strong></td><td>Wait 2+ weeks</td></tr>
</tbody></table>

</div>
<div class="section" id="s17">
  <div class="section-header"><h2><span class="icon">ğŸ§ </span> 17. Bayesian Basics</h2></div>
  
<div class="formula"><span class="label">Bayes' Theorem</span>P(A|B) = P(B|A) Â· P(A) / P(B) â†’ Posterior = Likelihood Ã— Prior / Evidence</div>
<pre><span class="lang">Python</span><code># Medical test: 99% accuracy, 1% prevalence
p_sick = 0.01
p_pos = 0.99 * 0.01 + 0.01 * 0.99
posterior = (0.99 * 0.01) / p_pos
print(f"P(Sick | Positive) = {posterior:.2%}")
print("â†’ Even 99% accurate test misleads with rare diseases!")</code></pre>
<div class="vs"><div class="vs-card"><h4>Frequentist</h4>
<ul><li>Probability = long-run frequency</li><li>Fixed parameter</li><li>p-value, confidence interval</li></ul></div>
<div class="vs-card"><h4>Bayesian</h4>
<ul><li>Probability = degree of belief</li><li>Random parameter</li><li>Posterior, credible interval</li></ul></div></div>

</div>
<div class="section" id="s18">
  <div class="section-header"><h2><span class="icon">ğŸ—ºï¸</span> 18. Which Test to Use?</h2></div>
  
<div class="tree">WHAT IS YOUR DATA TYPE?
â”‚
â”œâ”€â”€ Numerical (Continuous)
â”‚   â”œâ”€â”€ 1 Group        â†’ One-sample t-test
â”‚   â”œâ”€â”€ 2 Groups
â”‚   â”‚   â”œâ”€â”€ Independent â†’ Normal? â†’ Yes: t-test   | No: Mann-Whitney U
â”‚   â”‚   â””â”€â”€ Dependent   â†’ Normal? â†’ Yes: Paired t  | No: Wilcoxon
â”‚   â””â”€â”€ 3+ Groups
â”‚       â”œâ”€â”€ Independent â†’ Normal? â†’ Yes: ANOVA      | No: Kruskal-Wallis
â”‚       â””â”€â”€ Dependent   â†’ Repeated Measures ANOVA / Friedman
â”‚
â”œâ”€â”€ Categorical
â”‚   â”œâ”€â”€ One variable   â†’ Chi-Square Goodness of Fit
â”‚   â””â”€â”€ Two variables  â†’ Chi-Square Independence
â”‚
â””â”€â”€ Relationship
    â”œâ”€â”€ Linear?        â†’ Normal? â†’ Pearson r  | Spearman Ï
    â””â”€â”€ Prediction?    â†’ Regression (Simple / Multiple)</div>
<h3>Quick Checklist</h3>
<table><thead><tr><th>#</th><th>Step</th><th>Tool</th></tr></thead><tbody>
<tr><td>1</td><td>Identify data type</td><td><code>df.dtypes</code></td></tr>
<tr><td>2</td><td>Explore distribution</td><td>Histogram, QQ-plot</td></tr>
<tr><td>3</td><td>Test normality</td><td><code>shapiro()</code></td></tr>
<tr><td>4</td><td>Check variance</td><td><code>levene()</code></td></tr>
<tr><td>5</td><td>Apply test</td><td>Decision tree</td></tr>
<tr><td>6</td><td>Effect size</td><td>Cohen's d, Î·Â²</td></tr>
<tr><td>7</td><td>Report</td><td>p + effect + CI</td></tr>
</tbody></table>
<div class="warning"><strong>Golden Rule:</strong> p-value ALONE is not enough. Always report with effect size and confidence intervals!</div>

</div>
</div>
</body>
</html>